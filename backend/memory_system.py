"""
AIè®°å¿†å’Œå­¦ä¹ ç³»ç»Ÿ
é€šè¿‡å¯¹è¯ä¸æ–­æˆé•¿çš„AIåŠ©æ‰‹æ ¸å¿ƒç»„ä»¶
"""
import json
import sqlite3
from datetime import datetime
from typing import List, Dict, Any, Optional
import hashlib
from pathlib import Path

class ConversationMemory:
    """å¯¹è¯è®°å¿†ç³»ç»Ÿ - è®©AIä»æ¯æ¬¡å¯¹è¯ä¸­å­¦ä¹ """
    
    def __init__(self, db_path: str = "memory.db"):
        self.db_path = Path(db_path)
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–è®°å¿†æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å¯¹è¯è®°å½•è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversations (
            id TEXT PRIMARY KEY,
            session_id TEXT,
            user_message TEXT,
            assistant_response TEXT,
            timestamp DATETIME,
            user_feedback TEXT,
            context_used TEXT,
            topics TEXT,  -- JSON array of extracted topics
            sentiment REAL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # å­¦ä¹ åˆ°çš„çŸ¥è¯†è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS learned_knowledge (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            concept TEXT UNIQUE,
            description TEXT,
            examples TEXT,  -- JSON array
            source_conversations TEXT,  -- JSON array of conversation IDs
            confidence_score REAL DEFAULT 1.0,
            usage_count INTEGER DEFAULT 0,
            last_used DATETIME,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # ç”¨æˆ·åå¥½è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_preferences (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT,
            preference_type TEXT,  -- 'style', 'topic', 'complexity', etc.
            preference_value TEXT,
            confidence REAL DEFAULT 1.0,
            learned_from TEXT,  -- conversation_id
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # åé¦ˆè¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS feedback (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            conversation_id TEXT,
            feedback_type TEXT,  -- 'positive', 'negative', 'correction', 'suggestion'
            feedback_content TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (conversation_id) REFERENCES conversations (id)
        )
        ''')
        
        conn.commit()
        conn.close()
    
    def store_conversation(self, session_id: str, user_message: str, 
                          assistant_response: str, context_used: str = None,
                          topics: List[str] = None, sentiment: float = 0.5) -> str:
        """å­˜å‚¨å¯¹è¯è®°å½•"""
        conversation_id = hashlib.md5(
            f"{session_id}_{user_message}_{datetime.now().isoformat()}".encode()
        ).hexdigest()
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT INTO conversations 
        (id, session_id, user_message, assistant_response, timestamp, 
         context_used, topics, sentiment)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (conversation_id, session_id, user_message, assistant_response,
              datetime.now(), context_used, json.dumps(topics or []), sentiment))
        
        conn.commit()
        conn.close()
        
        # å¼‚æ­¥å­¦ä¹ å¤„ç†
        self._learn_from_conversation(conversation_id, user_message, assistant_response, topics)
        
        return conversation_id
    
    def _learn_from_conversation(self, conversation_id: str, user_message: str, 
                               assistant_response: str, topics: List[str] = None):
        """ä»å¯¹è¯ä¸­å­¦ä¹ æ–°çŸ¥è¯†"""
        # æå–æ¦‚å¿µå’Œæ¨¡å¼
        concepts = self._extract_concepts(user_message, assistant_response)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for concept, description in concepts.items():
            cursor.execute('''
            INSERT OR IGNORE INTO learned_knowledge 
            (concept, description, examples, source_conversations)
            VALUES (?, ?, ?, ?)
            ''', (concept, description, json.dumps([user_message]), 
                  json.dumps([conversation_id])))
            
            # æ›´æ–°å·²å­˜åœ¨çš„æ¦‚å¿µ
            cursor.execute('''
            UPDATE learned_knowledge 
            SET usage_count = usage_count + 1,
                last_used = ?,
                source_conversations = json_insert(
                    COALESCE(source_conversations, '[]'), 
                    '$[#]', ?
                )
            WHERE concept = ?
            ''', (datetime.now(), conversation_id, concept))
        
        conn.commit()
        conn.close()
    
    def _extract_concepts(self, user_message: str, assistant_response: str) -> Dict[str, str]:
        """ä»å¯¹è¯ä¸­æå–æ¦‚å¿µï¼ˆç®€å•å®ç°ï¼Œå¯ç”¨NLPå¢å¼ºï¼‰"""
        concepts = {}
        
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = ['å¦‚ä½•', 'ä»€ä¹ˆæ˜¯', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'æ–¹æ³•', 'æ­¥éª¤', 'æŠ€å·§']
        
        for keyword in keywords:
            if keyword in user_message:
                # æå–ä¸»é¢˜
                topic = user_message.replace(keyword, '').strip()
                if topic:
                    concepts[topic] = assistant_response[:200] + "..."
        
        return concepts
    
    def get_relevant_memory(self, query: str, session_id: str = None, limit: int = 5) -> List[Dict]:
        """è·å–ç›¸å…³çš„è®°å¿†"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦ï¼‰
        query_words = query.lower().split()
        conditions = []
        params = []
        
        for word in query_words:
            conditions.append("(LOWER(user_message) LIKE ? OR LOWER(assistant_response) LIKE ?)")
            params.extend([f"%{word}%", f"%{word}%"])
        
        where_clause = " AND ".join(conditions) if conditions else "1=1"
        
        if session_id:
            where_clause += " AND session_id = ?"
            params.append(session_id)
        
        cursor.execute(f'''
        SELECT * FROM conversations 
        WHERE {where_clause}
        ORDER BY timestamp DESC
        LIMIT ?
        ''', params + [limit])
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'id': row[0],
                'session_id': row[1],
                'user_message': row[2],
                'assistant_response': row[3],
                'timestamp': row[4],
                'context_used': row[5],
                'topics': json.loads(row[6]) if row[6] else []
            })
        
        conn.close()
        return results
    
    def add_feedback(self, conversation_id: str, feedback_type: str, content: str):
        """æ·»åŠ ç”¨æˆ·åé¦ˆ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT INTO feedback (conversation_id, feedback_type, feedback_content)
        VALUES (?, ?, ?)
        ''', (conversation_id, feedback_type, content))
        
        conn.commit()
        conn.close()
        
        # ä»åé¦ˆä¸­å­¦ä¹ 
        self._learn_from_feedback(conversation_id, feedback_type, content)
    
    def _learn_from_feedback(self, conversation_id: str, feedback_type: str, content: str):
        """ä»ç”¨æˆ·åé¦ˆä¸­å­¦ä¹ """
        # æ ¹æ®åé¦ˆè°ƒæ•´çŸ¥è¯†confidence_score
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if feedback_type == 'positive':
            # å¢åŠ ç›¸å…³æ¦‚å¿µçš„ä¿¡å¿ƒåˆ†æ•°
            cursor.execute('''
            UPDATE learned_knowledge 
            SET confidence_score = MIN(confidence_score * 1.1, 2.0)
            WHERE source_conversations LIKE ?
            ''', (f'%{conversation_id}%',))
        elif feedback_type == 'negative':
            # é™ä½ç›¸å…³æ¦‚å¿µçš„ä¿¡å¿ƒåˆ†æ•°
            cursor.execute('''
            UPDATE learned_knowledge 
            SET confidence_score = MAX(confidence_score * 0.9, 0.1)
            WHERE source_conversations LIKE ?
            ''', (f'%{conversation_id}%',))
        
        conn.commit()
        conn.close()
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ€»å¯¹è¯æ•°
        cursor.execute('SELECT COUNT(*) FROM conversations')
        total_conversations = cursor.fetchone()[0]
        
        # å­¦åˆ°çš„æ¦‚å¿µæ•°
        cursor.execute('SELECT COUNT(*) FROM learned_knowledge')
        learned_concepts = cursor.fetchone()[0]
        
        # æ”¶åˆ°çš„åé¦ˆæ•°
        cursor.execute('SELECT COUNT(*) FROM feedback')
        total_feedback = cursor.fetchone()[0]
        
        # æœ€æ´»è·ƒçš„æ¦‚å¿µ
        cursor.execute('''
        SELECT concept, usage_count, confidence_score 
        FROM learned_knowledge 
        ORDER BY usage_count DESC 
        LIMIT 5
        ''')
        top_concepts = cursor.fetchall()
        
        conn.close()
        
        return {
            'total_conversations': total_conversations,
            'learned_concepts': learned_concepts,
            'total_feedback': total_feedback,
            'top_concepts': [
                {'concept': c[0], 'usage': c[1], 'confidence': c[2]}
                for c in top_concepts
            ]
        }

class AdaptivePersonality:
    """è‡ªé€‚åº”ä¸ªæ€§ç³»ç»Ÿ - æ ¹æ®ç”¨æˆ·äº’åŠ¨è°ƒæ•´å›åº”é£æ ¼"""
    
    def __init__(self, memory: ConversationMemory):
        self.memory = memory
    
    def analyze_user_style(self, session_id: str) -> Dict[str, float]:
        """åˆ†æç”¨æˆ·çš„äº¤æµé£æ ¼"""
        conn = sqlite3.connect(self.memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT user_message FROM conversations 
        WHERE session_id = ? 
        ORDER BY timestamp DESC 
        LIMIT 20
        ''', (session_id,))
        
        messages = [row[0] for row in cursor.fetchall()]
        conn.close()
        
        if not messages:
            return {'formality': 0.5, 'detail_level': 0.5, 'friendliness': 0.5}
        
        # ç®€å•çš„é£æ ¼åˆ†æ
        total_chars = sum(len(msg) for msg in messages)
        avg_length = total_chars / len(messages)
        
        # æ­£å¼åº¦åˆ†æ
        formal_words = ['è¯·', 'æ‚¨', 'è°¢è°¢', 'éº»çƒ¦']
        informal_words = ['å—¯', 'å“ˆ', 'å‘€', 'å§']
        
        formal_score = sum(1 for msg in messages for word in formal_words if word in msg)
        informal_score = sum(1 for msg in messages for word in informal_words if word in msg)
        
        formality = formal_score / (formal_score + informal_score + 1)
        
        return {
            'formality': formality,
            'detail_level': min(avg_length / 50, 1.0),  # 0-1 based on message length
            'friendliness': informal_score / len(messages) if messages else 0.5
        }
    
    def adapt_response_style(self, base_response: str, user_style: Dict[str, float]) -> str:
        """æ ¹æ®ç”¨æˆ·é£æ ¼è°ƒæ•´å›åº”"""
        adapted_response = base_response
        
        # æ ¹æ®æ­£å¼åº¦è°ƒæ•´
        if user_style['formality'] > 0.7:
            adapted_response = adapted_response.replace('ä½ ', 'æ‚¨')
            adapted_response += "\n\nå¦‚æœ‰å…¶ä»–éœ€è¦ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚"
        elif user_style['formality'] < 0.3:
            adapted_response += " ğŸ˜Š"
        
        # æ ¹æ®è¯¦ç»†ç¨‹åº¦è°ƒæ•´
        if user_style['detail_level'] > 0.7:
            adapted_response += "\n\néœ€è¦æˆ‘è¿›ä¸€æ­¥è¯¦ç»†è§£é‡Šä»»ä½•éƒ¨åˆ†å—ï¼Ÿ"
        
        return adapted_response

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
    memory = ConversationMemory()
    personality = AdaptivePersonality(memory)
    
    # å­˜å‚¨å¯¹è¯
    conv_id = memory.store_conversation(
        "user123", 
        "å¦‚ä½•è®©AIåŠ©æ‰‹å˜å¾—æ›´æ™ºèƒ½ï¼Ÿ", 
        "å¯ä»¥é€šè¿‡å¤šç§æ–¹æ³•ï¼š1. æŒç»­å­¦ä¹ å¯¹è¯å†å² 2. æ”¶é›†ç”¨æˆ·åé¦ˆ...",
        topics=["AIå­¦ä¹ ", "æ™ºèƒ½åŒ–"]
    )
    
    # æ·»åŠ åé¦ˆ
    memory.add_feedback(conv_id, "positive", "å›ç­”å¾ˆæœ‰å¸®åŠ©")
    
    # è·å–å­¦ä¹ ç»Ÿè®¡
    stats = memory.get_learning_stats()
    print("å­¦ä¹ ç»Ÿè®¡:", stats)