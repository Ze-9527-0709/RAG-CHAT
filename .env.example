# RAG Chat App Environment Variables
# Copy this file to .env and fill in your actual values

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Pinecone Configuration  
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=your_index_name_here
EMBEDDING_MODEL=text-embedding-3-small

# Model Fallback Settings
OPENAI_ESTIMATED_BALANCE=25.50    # Your current OpenAI balance ($)
MIN_OPENAI_BALANCE=5.00           # Minimum balance before switching to cheaper models ($)
MAX_MODEL_RETRIES=2               # Max retries per model before fallback
QUOTA_CHECK_INTERVAL=300          # Seconds between quota checks (5 minutes)

# Local Model Settings (Optional - for Ollama)
LOCAL_MODEL_ENDPOINT=http://localhost:11434/api/generate
LOCAL_MODEL_NAME=llama2-7b-chat

# Development Settings
DEBUG=false
LOG_LEVEL=INFO